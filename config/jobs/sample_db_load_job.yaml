name: parquet_to_mysql
description: Load processed data from Parquet into MySQL database

extract:
  type: parquet
  options:
    path: data/output/processed_data

transform:
  - type: column
    options:
      type: add_column
      column_name: load_timestamp
      expression: "current_timestamp()"

load:
  type: database
  options:
    db_type: mysql
    host: localhost
    port: 3306
    database: analytics_db
    table: processed_users
    
    # Write mode: append/overwrite/error/ignore
    mode: append
    
    # Optional: Schema evolution
    merge_schema: true
    
    # Optional: Provide credentials in config (otherwise will look for environment variables)
    # username: myuser
    # password: mypassword
    
    # Performance tuning options
    jdbc_options:
      batchsize: 1000
      num_partitions: 4
      isolation_level: REPEATABLE_READ
      
      # MySQL-specific options
      rewrite_batched_statements: true
      use_server_prep_stmts: true
      cache_prep_stmts: true

spark_config:
  app_name: DatabaseLoadJob
  master: local[*]
  configs:
    spark.sql.shuffle.partitions: 10
    spark.executor.memory: 2g 